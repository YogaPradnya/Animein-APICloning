# Opsi Tanpa Playwright untuk Vercel (Tetap Pakai JS)

## ğŸ¯ Masalah Utama
Halaman schedule pakai **Next.js (client-side rendering)**, jadi perlu browser automation untuk scrape. Tapi Playwright terlalu berat untuk Vercel.

---

## âœ… OPSI 1: Puppeteer dengan @sparticuz/chromium (RECOMMENDED)

**Status:** âœ… BISA di Vercel
**Kompleksitas:** Medium
**Biaya:** Gratis

### Kelebihan:
- âœ… Support JavaScript rendering
- âœ… Bisa scrape schedule dengan benar
- âœ… Optimized untuk serverless (Vercel)
- âœ… Tetap pakai JS

### Kekurangan:
- âš ï¸ Perlu setup khusus
- âš ï¸ Memory usage tinggi (~200-300MB)
- âš ï¸ Bisa timeout kalau terlalu lama

### Implementasi:
```javascript
const puppeteer = require('puppeteer-core');
const chromium = require('@sparticuz/chromium');

const browser = await puppeteer.launch({
  args: chromium.args,
  defaultViewport: chromium.defaultViewport,
  executablePath: await chromium.executablePath(),
  headless: chromium.headless,
});
```

**Note:** Sudah pernah dicoba tapi error. Perlu fix konfigurasi.

---

## âœ… OPSI 2: Headless Browser Service Eksternal

**Status:** âœ… BISA di Vercel
**Kompleksitas:** Easy
**Biaya:** Ada yang gratis, ada yang bayar

### Service yang Tersedia:

#### A. Browserless.io (Free tier: 6 jam/bulan)
```javascript
const axios = require('axios');

const response = await axios.post('https://chrome.browserless.io/content', {
  url: 'https://animeinweb.com/schedule',
  waitFor: 2000
}, {
  headers: {
    'Authorization': `Bearer ${process.env.BROWSERLESS_TOKEN}`
  }
});
```

#### B. ScraperAPI (Free tier: 1000 requests/bulan)
```javascript
const axios = require('axios');

const response = await axios.get('http://api.scraperapi.com', {
  params: {
    api_key: process.env.SCRAPERAPI_KEY,
    url: 'https://animeinweb.com/schedule',
    render: 'true' // JavaScript rendering
  }
});
```

#### C. ScrapingBee (Free tier: 1000 requests/bulan)
```javascript
const axios = require('axios');

const response = await axios.get('https://app.scrapingbee.com/api/v1/', {
  params: {
    api_key: process.env.SCRAPINGBEE_KEY,
    url: 'https://animeinweb.com/schedule',
    render_js: 'true'
  }
});
```

### Kelebihan:
- âœ… Tidak perlu install browser
- âœ… Tidak makan memory di Vercel
- âœ… Reliable dan cepat
- âœ… Support JavaScript rendering

### Kekurangan:
- âš ï¸ Perlu API key (ada free tier)
- âš ï¸ Rate limit di free tier
- âš ï¸ Dependency eksternal

---

## âœ… OPSI 3: Cari API Endpoint Lain

**Status:** âš ï¸ BELUM DITEMUKAN
**Kompleksitas:** Easy (kalau ketemu)
**Biaya:** Gratis

### Yang Sudah Dicoba:
- âŒ `/api/proxy/3/2/explore/movie` - Tidak punya data per hari
- âŒ `/api/proxy/3/2/schedule` - Tidak ada endpoint
- âŒ `/api/proxy/3/2/movie/schedule` - Tidak ada endpoint

### Yang Bisa Dicoba:
```javascript
// Coba endpoint-endpoint ini:
const endpoints = [
  'https://animeinweb.com/api/proxy/3/2/schedule/movie',
  'https://animeinweb.com/api/proxy/3/2/movie/list?day=MONDAY',
  'https://animeinweb.com/api/proxy/3/2/calendar',
  'https://animeinweb.com/api/proxy/3/2/timetable',
];
```

**Note:** Perlu investigasi lebih lanjut untuk cari endpoint yang punya data schedule per hari.

---

## âœ… OPSI 4: Hybrid Approach (Vercel + Service Eksternal)

**Status:** âœ… BISA di Vercel
**Kompleksitas:** Medium
**Biaya:** Gratis (pakai free tier)

### Konsep:
- **Vercel:** Handle API endpoints yang tidak perlu browser
- **Service Eksternal:** Handle scraping schedule (via API call)

### Implementasi:
```javascript
// Di Vercel
async function getSchedule(day = null) {
  if (process.env.VERCEL) {
    // Pakai service eksternal untuk scraping
    const response = await axios.post('https://chrome.browserless.io/content', {
      url: `https://animeinweb.com/schedule?day=${day}`,
      waitFor: 2000
    }, {
      headers: {
        'Authorization': `Bearer ${process.env.BROWSERLESS_TOKEN}`
      }
    });
    
    // Parse HTML response
    const $ = cheerio.load(response.data);
    // ... extract data
  }
}
```

---

## âœ… OPSI 5: Pre-render & Cache (Workaround)

**Status:** âœ… BISA di Vercel
**Kompleksitas:** Medium
**Biaya:** Gratis

### Konsep:
- Scrape schedule sekali sehari (pakai cron job atau scheduled function)
- Simpan hasil ke cache/database
- API hanya return data dari cache

### Implementasi:
```javascript
// Scheduled function (Vercel Cron Jobs)
// Run setiap hari jam 00:00 UTC
export default async function handler(req, res) {
  // Scrape schedule untuk semua hari
  const schedule = await scrapeScheduleWithService();
  
  // Simpan ke cache/database
  await saveToCache(schedule);
  
  return res.json({ success: true });
}

// API endpoint hanya return dari cache
app.get('/api/v1/animeinweb/schedule', async (req, res) => {
  const schedule = await getFromCache(req.query.day);
  return res.json({ success: true, data: schedule });
});
```

**Note:** Perlu setup Vercel Cron Jobs atau external cron service.

---

## ğŸ“Š PERBANDINGAN OPSI

| Opsi | Kompleksitas | Biaya | Reliability | Schedule Accuracy |
|------|-------------|-------|-------------|-------------------|
| Puppeteer + Chromium | Medium | Gratis | âš ï¸ Medium | âœ… Akurat |
| Browserless.io | Easy | Free tier | âœ… High | âœ… Akurat |
| ScraperAPI | Easy | Free tier | âœ… High | âœ… Akurat |
| ScrapingBee | Easy | Free tier | âœ… High | âœ… Akurat |
| Cari API Endpoint | Easy | Gratis | â“ Unknown | â“ Unknown |
| Pre-render & Cache | Medium | Gratis | âœ… High | âš ï¸ Update sekali/hari |

---

## ğŸ† REKOMENDASI

### Untuk Production:
**Opsi 2: Browserless.io atau ScraperAPI**
- âœ… Paling reliable
- âœ… Tidak makan resource Vercel
- âœ… Support JavaScript rendering
- âœ… Free tier cukup untuk development

### Untuk Development:
**Opsi 1: Puppeteer + Chromium**
- âœ… Gratis
- âœ… Tidak perlu dependency eksternal
- âš ï¸ Perlu fix konfigurasi

### Untuk Long-term:
**Opsi 5: Pre-render & Cache**
- âœ… Paling efisien
- âœ… Tidak perlu scrape setiap request
- âœ… Bisa update sekali sehari

---

## ğŸ’¡ IMPLEMENTASI CEPAT: Browserless.io

### Setup:
1. Daftar di https://browserless.io (free tier)
2. Dapatkan API token
3. Tambahkan ke Vercel environment variables

### Code:
```javascript
const axios = require('axios');

async function scrapeScheduleWithBrowserless(day = null) {
  const url = day 
    ? `https://animeinweb.com/schedule?day=${day}`
    : 'https://animeinweb.com/schedule';
  
  const response = await axios.post(
    'https://chrome.browserless.io/content',
    {
      url: url,
      waitFor: 2000, // Wait 2 seconds for JS to render
      gotoOptions: {
        waitUntil: 'networkidle0'
      }
    },
    {
      headers: {
        'Authorization': `Bearer ${process.env.BROWSERLESS_TOKEN}`,
        'Content-Type': 'application/json'
      },
      timeout: 30000
    }
  );
  
  // Parse HTML dengan Cheerio
  const $ = cheerio.load(response.data);
  // ... extract schedule data
  
  return scheduleData;
}
```

---

## ğŸ¯ KESIMPULAN

**Opsi Terbaik untuk Vercel:**
1. **Browserless.io** (paling mudah dan reliable)
2. **ScraperAPI** (alternatif yang bagus)
3. **Puppeteer + Chromium** (kalau mau fix konfigurasi)

Semua opsi ini:
- âœ… Tetap pakai JS
- âœ… Bisa di Vercel
- âœ… Tidak perlu Playwright
- âœ… Bisa scrape JavaScript-rendered content

